{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Images Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['botolkaca',\n",
       " 'botolplastik',\n",
       " 'kaleng',\n",
       " 'kardus',\n",
       " 'karet',\n",
       " 'kertas',\n",
       " 'plastik',\n",
       " 'sedotan']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLLECTED_IMG_PATH = r'.\\Tensorflow\\workspace\\images\\collectedimages'\n",
    "\n",
    "labels = os.listdir(COLLECTED_IMG_PATH)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    !mkdir {IMAGES_PATH}\n",
    "        \n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in c:\\users\\user\\anaconda3\\lib\\site-packages (5.15.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyqt5) (12.10.1)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyqt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nanti muncul python gui, pakai python gui itu buat extract fitur\n",
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "botolkaca \t= 353\n",
      "botolplastik \t= 311\n",
      "kaleng \t\t= 220\n",
      "kardus \t\t= 137\n",
      "karet \t\t= 147\n",
      "kertas \t\t= 275\n",
      "plastik \t= 232\n",
      "sedotan \t= 28\n"
     ]
    }
   ],
   "source": [
    "# Melihat jumlah foto yang kita punya\n",
    "for label in labels:\n",
    "    print(label, '\\t=' if len(label) > 6 else '\\t\\t=' , int(len(os.listdir(os.path.join(COLLECTED_IMG_PATH, label)))/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Copy them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First delete the contents of the train and test directories!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_PATH):\n",
    "    os.mkdir(TRAIN_PATH)\n",
    "\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    os.mkdir(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Hasea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and copy collected image to train and test dir\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "TRAIN_TO_TOTAL_RATIO = 0.8\n",
    "\n",
    "\n",
    "for file_folder_name in labels:\n",
    "    file_dir = os.path.join(IMAGES_PATH, file_folder_name)\n",
    "    xml_list = [file for file in os.listdir(file_dir) if file.endswith('xml')]\n",
    "    train_num = int((TRAIN_TO_TOTAL_RATIO*len(xml_list))//1)\n",
    "    file_for_training = list(random.sample(xml_list, train_num))\n",
    "    file_for_test = [file for file in xml_list if file not in file_for_training]\n",
    "    \n",
    "    for file in file_for_training:\n",
    "        file_xml = os.path.join(file_dir, file)\n",
    "        file_jpg = os.path.join(file_dir, file[:-3]) + 'jpg'\n",
    "        jpg_target = os.path.join(TRAIN_PATH, file[:-3]) + 'jpg'\n",
    "        xml_target = os.path.join(TRAIN_PATH, file)\n",
    "        shutil.copyfile(file_xml, xml_target)\n",
    "        shutil.copyfile(file_jpg, jpg_target)\n",
    "    \n",
    "    for file in file_for_test:\n",
    "        file_xml = os.path.join(file_dir, file)\n",
    "        file_jpg = os.path.join(file_dir, file[:-3]) + 'jpg'\n",
    "        jpg_target = os.path.join(TEST_PATH, file[:-3]) + 'jpg'\n",
    "        xml_target = os.path.join(TEST_PATH, file)\n",
    "        shutil.copyfile(file_xml, xml_target)\n",
    "        shutil.copyfile(file_jpg, jpg_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Krisna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "botolkaca 706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9228\\1514036187.py:26: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data_name_temp = np.array(list(set(data_name_temp)), dtype=np.str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "botolplastik 622\n",
      "kaleng 440\n",
      "kardus 274\n",
      "karet 294\n",
      "kertas 550\n",
      "plastik 464\n",
      "sedotan 52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "import shutil\n",
    "\n",
    "np.random.seed(101)\n",
    "# moving random data from classes folder to test and train\n",
    "test_size = .1\n",
    "pattern1 = r'(.*)\\.[jpg|xml]'\n",
    "\n",
    "for label_dir in os.listdir(IMAGES_PATH):\n",
    "    label_dir_path = os.path.join(IMAGES_PATH, label_dir)\n",
    "    num_files = len( os.listdir( label_dir_path ) )\n",
    "    print(label_dir, num_files)\n",
    "    \n",
    "    if num_files == 0:\n",
    "        print(f'{label_dir} is copied, continue ...')\n",
    "        continue\n",
    "    \n",
    "    # Karena ada 2 ekstensi file untuk 1 foto (jpg dan xml) \n",
    "    # maka diambil set nya\n",
    "    data_name_temp = []\n",
    "    for data in os.listdir(label_dir_path):\n",
    "        searched = re.search(pattern1, data)\n",
    "        data_name_temp.append(searched.groups()[0])\n",
    "    \n",
    "    data_name_temp = np.array(list(set(data_name_temp)), dtype=np.str)\n",
    "    \n",
    "    # untuk setiap data akan diacak \n",
    "    np.random.shuffle(data_name_temp)\n",
    "    \n",
    "    # Todo: Melakukan pengambilan data \n",
    "    break_point = int(len(data_name_temp) * test_size)\n",
    "    \n",
    "    test_candidate = data_name_temp[:break_point]\n",
    "    \n",
    "    # untuk setiap kandidat data test akan dipindahkan ke folder test \n",
    "    for data_test in test_candidate:\n",
    "        # melakukan pencarian tiap data test pada direktori label dir path\n",
    "        pattern2 = r'(' + data_test + r'\\.[xmljpg]*)'\n",
    "        \n",
    "        for train_test_data in os.listdir(label_dir_path):\n",
    "            searched = re.search(pattern2, train_test_data)\n",
    "            # kalau bukan none maka test\n",
    "            if searched is not None:\n",
    "                test_data_use = searched.groups()[0]\n",
    "                source_path = os.path.join(label_dir_path, test_data_use)\n",
    "                # print(\"Test : \", source_path)\n",
    "                shutil.copy(source_path, TEST_PATH)\n",
    "            # jika none maka train\n",
    "            else:\n",
    "                source_path = os.path.join(label_dir_path, train_test_data)\n",
    "                # print(\"Train : \", source_path)\n",
    "                shutil.copy(source_path, TRAIN_PATH)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek ukuran test dan train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 3400 data\n",
      "Test data : 310 data\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data : {len(os.listdir(TRAIN_PATH))} data\")\n",
    "print(f\"Test data : {len(os.listdir(TEST_PATH))} data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OPSIONAL) 7. File tar jika mau menyimpan data dalam bentuk TAR dan diakses dari Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        for source in source_dir:\n",
    "            tar.add(source, arcname=os.path.basename(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tarfile(ARCHIVE_PATH, [TRAIN_PATH, TEST_PATH])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
